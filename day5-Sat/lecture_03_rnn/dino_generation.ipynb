{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#some useful imports \n",
    "import nltk\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aachenosaurus', 'aardonyx', 'abdallahsaurus', 'abelisaurus', 'abrictosaurus', 'abrosaurus', 'abydosaurus', 'acanthopholis', 'achelousaurus', 'acheroraptor']\n"
     ]
    }
   ],
   "source": [
    "#reading the data in\n",
    "names = [name.strip().lower() for name in open('dinos.txt').readlines()]\n",
    "print(names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphabet is a list of unique characters\n",
    "chars = [char for name in names for char in name] + ['bos','eos']\n",
    "alphabet = list(set(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#data preporation\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "X_names = ['bos ' + ' '.join(name) for name in names]\n",
    "Y_names = [' '.join(name) + ' eos' for name in names]\n",
    "maxlen = max([len(name) for name in names])+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Teacher forcing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos a a c h e n o s a u r u s\n",
      "a a c h e n o s a u r u s eos\n"
     ]
    }
   ],
   "source": [
    "print(X_names[0])\n",
    "print(Y_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(alphabet)+2)\n",
    "tokenizer.fit_on_texts(X_names+Y_names)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_names)\n",
    "X_train = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(Y_names)\n",
    "Y_train = pad_sequences(sequences, padding='post')\n",
    "\n",
    "\n",
    "Y_train_cat  = [to_categorical(sent, num_classes=len(alphabet)+2) for sent in Y_train]\n",
    "Y_train =  np.asarray(Y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos a a c h e n o s a u r u s\n",
      "a a c h e n o s a u r u s eos\n",
      "(1536, 27)\n",
      "(1536, 27, 30)\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(X_names[0])\n",
    "print(Y_names[0])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "print(tokenizer.word_index['bos'])\n",
    "print(tokenizer.word_index['eos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "char_index = tokenizer.word_index\n",
    "index_char = {i: c for c, i in char_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#the RNN language model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(alphabet)+2, 30, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "\n",
    "model.add(Dense(len(alphabet)+2, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 3.3988 - acc: 0.0089\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 600us/step - loss: 3.3849 - acc: 0.3924\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 619us/step - loss: 3.3700 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 602us/step - loss: 3.3532 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 583us/step - loss: 3.3335 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 579us/step - loss: 3.3094 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 577us/step - loss: 3.2789 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 580us/step - loss: 3.2389 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 571us/step - loss: 3.1847 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 587us/step - loss: 3.1086 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 599us/step - loss: 2.9974 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 639us/step - loss: 2.8302 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 638us/step - loss: 2.5826 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 747us/step - loss: 2.2696 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 630us/step - loss: 1.9904 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 680us/step - loss: 1.8192 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 575us/step - loss: 1.7547 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 572us/step - loss: 1.7692 - acc: 0.5199\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 618us/step - loss: 1.8217 - acc: 0.5199\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 20):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, Y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# helper function to sample an index from a probability array\n",
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) #/ temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.choice(range(len(alphabet)+2), p = preds)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"bos\"\n",
      "bos \n",
      "bos n \n",
      "bos n g \n",
      "bos n g e \n",
      "bos n g e v \n",
      "bos n g e v p \n",
      "bos n g e v p k \n",
      "bos n g e v p k h \n"
     ]
    }
   ],
   "source": [
    "#generation \n",
    "generated = ''\n",
    "seed = 'bos'\n",
    "generated += seed + ' '\n",
    "print('----- Generating with seed: \"' + seed + '\"')\n",
    "print(generated)\n",
    "\n",
    "\n",
    "for i in range(7): \n",
    "    sequences = tokenizer.texts_to_sequences([seed])\n",
    "    X_pred = pad_sequences(sequences, maxlen=maxlen, padding = 'post')\n",
    "\n",
    "    preds = model.predict(X_pred, verbose=0)[0]\n",
    "    samples = [sample(p) for p in preds]\n",
    "    next_index = samples[i]\n",
    "    while next_index == 0 or next_index == 10:\n",
    "        samples = [sample(p) for p in preds]\n",
    "        next_index = samples[i]\n",
    "    next_char = index_char[next_index+1]\n",
    "    generated += next_char + ' '\n",
    "    print(generated)\n",
    "    seed += next_char\n",
    "    if next_char == 'eos':\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
